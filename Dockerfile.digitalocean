# Dockerfile.jupyter
FROM --platform=linux/amd64 python:3.12.7-slim

# Install system dependencies, IPFS, and build tools
# build-essential: Provides GCC compiler and build tools for C extensions
# python3-dev: Includes Python headers needed for building C extensions
# libffi-dev: Required for Foreign Function Interface
# libssl-dev: Needed for cryptographic operations
RUN apt-get update && apt-get install -y \
    git \
    curl \
    wget \
    build-essential \
    python3-dev \
    python3-venv \
    libffi-dev \
    libssl-dev \
    && rm -rf /var/lib/apt/lists/*

ARG KUBO_VERSION=0.33.2

# Install IPFS with architecture detection
RUN arch=$(uname -m) && \
    if [ "$arch" = "aarch64" ]; then \
    IPFS_ARCH="arm64"; \
    else \
    IPFS_ARCH="amd64"; \
    fi && \
    wget "https://dist.ipfs.tech/kubo/v${KUBO_VERSION}/kubo_v${KUBO_VERSION}_linux-${IPFS_ARCH}.tar.gz" && \
    tar -xvzf "kubo_v${KUBO_VERSION}_linux-${IPFS_ARCH}.tar.gz" && \
    cd kubo && \
    bash install.sh && \
    cd .. && \
    rm -rf "kubo_v${KUBO_VERSION}_linux-${IPFS_ARCH}.tar.gz"

# <----------------- UV installation ----------------->
# The installer requires curl (and certificates) to download the release archive
RUN apt-get update && apt-get install -y --no-install-recommends curl ca-certificates

# Download the latest installer
ADD https://astral.sh/uv/install.sh /uv-installer.sh

# Run the installer then remove it
RUN sh /uv-installer.sh && rm /uv-installer.sh

# Ensure the installed binary is on the `PATH`
ENV PATH="/root/.local/bin/:$PATH"

# <----------------- End of UV installation ----------------->

# Create a directory for UV virtual environment
# We use UV's native virtual environment instead of venv
ENV VIRTUAL_ENV=/opt/venv
RUN uv venv $VIRTUAL_ENV

# Add virtual environment to PATH
ENV PATH="$VIRTUAL_ENV/bin:$PATH"

# Install base packages using UV
COPY requirements.txt .
RUN uv pip install --no-cache -r requirements.txt

# Create requirements directory
RUN mkdir -p /opt/requirements

# Initialize IPFS with default settings and enable AutoTLS
RUN ipfs init && \
    ipfs config --json AutoTLS '{"Enabled": true, "AutoWSS": true}'

# Set up working directory
WORKDIR /notebooks

# Create notebooks directory if it doesn't exist
RUN mkdir -p /notebooks

# Expose ports for Jupyter and IPFS
# Jupyter
EXPOSE 8888 
# IPFS swarm
EXPOSE 4001  
# IPFS API
EXPOSE 5001  
# IPFS Gateway
EXPOSE 8080 

# Create scripts directory and copy startup scripts
RUN mkdir -p /scripts

# Copy the startup script content directly
RUN echo '#!/bin/bash\n\
# Debug deployment info\n\
echo "=== Digital Ocean App Platform Deployment ==="\n\
echo "Working Directory: $(pwd)"\n\
echo "Notebook Directory Contents:"\n\
ls -la /notebooks\n\
\n\
# Enable AutoTLS debug logging\n\
export GOLOG_LOG_LEVEL="error,autotls=debug"\n\
\n\
# Retrieve the peer ID from IPFS config\n\
PEER_ID=$(ipfs config Identity.PeerID)\n\
if [ -z "$PEER_ID" ]; then\n\
    echo "Error: Unable to retrieve peer ID. Make sure your IPFS node is initialized."\n\
    exit 1\n\
fi\n\
echo "Using peer ID: $PEER_ID"\n\
\n\
# Digital Ocean App Platform specific configuration\n\
echo "Configuring IPFS for Digital Ocean App Platform..."\n\
\n\
# Get the public-facing URL assigned by Digital Ocean\n\
if [ -n "$APP_URL" ]; then\n\
    APP_DOMAIN=$(echo "$APP_URL" | sed '"'"'s|^https?://||'"'"' | sed '"'"'s|/.*$||'"'"')\n\
    \n\
    echo "App domain: $APP_DOMAIN"\n\
    \n\
    # Configure announce addresses\n\
    DO_ANNOUNCE_ADDRS="[\"/dns4/$APP_DOMAIN/tcp/443/https\"]"\n\
    echo "Setting announce addresses: $DO_ANNOUNCE_ADDRS"\n\
    ipfs config --json Addresses.Announce "$DO_ANNOUNCE_ADDRS"\n\
else\n\
    echo "No APP_URL environment variable found"\n\
fi\n\
\n\
# Disable NAT port mapping in cloud environment\n\
ipfs config --json Swarm.DisableNatPortMap true\n\
\n\
# Enable AutoTLS settings.\n\
ipfs config --json AutoTLS.Enabled true\n\
ipfs config --json AutoTLS.AutoWSS true\n\
\n\
echo "Current AutoTLS configuration:"\n\
ipfs config AutoTLS\n\
\n\
# Start IPFS daemon in the background\n\
echo "Starting IPFS daemon..."\n\
ipfs daemon --enable-pubsub-experiment --migrate=true &\n\
\n\
# Wait for IPFS to start\n\
sleep 5\n\
\n\
# Determine Jupyter token\n\
JUPYTER_TOKEN_VALUE=${JUPYTER_TOKEN:-"default_token"}\n\
echo "Using Jupyter token: $JUPYTER_TOKEN_VALUE"\n\
\n\
# Start Jupyter Lab\n\
echo "Starting Jupyter Lab..."\n\
jupyter lab --ip=0.0.0.0 --port=8888 --no-browser --allow-root --NotebookApp.token="$JUPYTER_TOKEN_VALUE" --NotebookApp.allow_origin='"'"'*'"'"'' > /scripts/digitalocean_start.sh

# Create a basic install_packages.sh script
RUN echo '#!/bin/bash\n\
# Check if there are any additional requirement files\n\
if [ -d "/opt/requirements" ]; then\n\
    for req in /opt/requirements/*.txt; do\n\
        if [ -f "$req" ]; then\n\
            echo "Installing packages from $req"\n\
            uv pip install --no-cache -r "$req"\n\
        fi\n\
    done\n\
fi' > /scripts/install_packages.sh

# Make scripts executable
RUN chmod +x /scripts/digitalocean_start.sh /scripts/install_packages.sh

# Set Digital Ocean specific environment variables
ENV DO_APP_PLATFORM=true

# Use CMD instead of ENTRYPOINT for Digital Ocean App Platform compatibility
CMD ["/bin/bash", "/scripts/digitalocean_start.sh"]