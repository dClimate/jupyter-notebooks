{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5a64bec-93ac-401d-b634-fd8437b3d380",
   "metadata": {},
   "source": [
    "# Creating an Encryption ETL - CPC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8979b10-4ad8-4e94-80ec-4e32d34785ff",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Welcome to the [dClimate](https://www.dclimate.net/) Encryption with [py-hamt](https://github.com/dClimate/py-hamt) - CPC Jupyter notebook. This notebook describes how to create an [ETL](https://en.wikipedia.org/wiki/Extract,_transform,_load) to ingest GIS data into IPFS from a remote source and encrypt it. If you have not read the [Getting Started](./Getting%20Started.ipynb) notebook we highly suggest you first go through that notebook in order to understand everything below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75a0119f-d6fb-463d-af7c-dd0b1f992a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.7 environment at: /opt/venv\u001b[0m\n",
      "\u001b[2mResolved \u001b[1m37 packages\u001b[0m \u001b[2min 616ms\u001b[0m\u001b[0m                                            \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m37 packages\u001b[0m \u001b[2min 143ms\u001b[0m\u001b[0m                                            \n",
      "\u001b[2mUninstalled \u001b[1m37 packages\u001b[0m \u001b[2min 298ms\u001b[0m\u001b[0m\n",
      "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mFailed to hardlink files; falling back to full copy. This may lead to degraded performance.\n",
      "         If the cache and target directories are on different filesystems, hardlinking may not be supported.\n",
      "         If this is intentional, set `export UV_LINK_MODE=copy` or use `--link-mode=copy` to suppress this warning.\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m37 packages\u001b[0m \u001b[2min 350ms\u001b[0m\u001b[0m                              \u001b[0m\n",
      " \u001b[33m~\u001b[39m \u001b[1mbases\u001b[0m\u001b[2m==0.3.0\u001b[0m\n",
      " \u001b[33m~\u001b[39m \u001b[1mblake3\u001b[0m\u001b[2m==1.0.4\u001b[0m\n",
      " \u001b[33m~\u001b[39m \u001b[1mcertifi\u001b[0m\u001b[2m==2025.1.31\u001b[0m\n",
      " \u001b[33m~\u001b[39m \u001b[1mcharset-normalizer\u001b[0m\u001b[2m==3.4.1\u001b[0m\n",
      " \u001b[33m~\u001b[39m \u001b[1mcrc32c\u001b[0m\u001b[2m==2.7.1\u001b[0m\n",
      " \u001b[33m~\u001b[39m \u001b[1mdag-cbor\u001b[0m\u001b[2m==0.3.3\u001b[0m\n",
      " \u001b[33m~\u001b[39m \u001b[1mdeprecated\u001b[0m\u001b[2m==1.2.18\u001b[0m\n",
      " \u001b[33m~\u001b[39m \u001b[1mdonfig\u001b[0m\u001b[2m==0.8.1.post1\u001b[0m\n",
      " \u001b[33m~\u001b[39m \u001b[1midna\u001b[0m\u001b[2m==3.10\u001b[0m\n",
      " \u001b[33m~\u001b[39m \u001b[1mmarkdown-it-py\u001b[0m\u001b[2m==3.0.0\u001b[0m\n",
      " \u001b[33m~\u001b[39m \u001b[1mmdurl\u001b[0m\u001b[2m==0.1.2\u001b[0m\n",
      " \u001b[33m~\u001b[39m \u001b[1mmmh3\u001b[0m\u001b[2m==5.1.0\u001b[0m\n",
      " \u001b[33m~\u001b[39m \u001b[1mmsgspec\u001b[0m\u001b[2m==0.19.0\u001b[0m\n",
      " \u001b[33m~\u001b[39m \u001b[1mmultiformats\u001b[0m\u001b[2m==0.3.1.post4\u001b[0m\n",
      " \u001b[33m~\u001b[39m \u001b[1mmultiformats-config\u001b[0m\u001b[2m==0.3.1\u001b[0m\n",
      " \u001b[33m~\u001b[39m \u001b[1mnumcodecs\u001b[0m\u001b[2m==0.15.1\u001b[0m\n",
      " \u001b[33m~\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.2.4\u001b[0m\n",
      " \u001b[33m~\u001b[39m \u001b[1mpackaging\u001b[0m\u001b[2m==24.2\u001b[0m\n",
      " \u001b[33m~\u001b[39m \u001b[1mpandas\u001b[0m\u001b[2m==2.2.3\u001b[0m\n",
      " \u001b[33m~\u001b[39m \u001b[1mpy-hamt\u001b[0m\u001b[2m==2.4.0 (from git+https://github.com/dClimate/py-hamt.git@3ac5d99d537b4727480ff388f91d2dc0e7b9a58b)\u001b[0m\n",
      " \u001b[33m~\u001b[39m \u001b[1mpycryptodome\u001b[0m\u001b[2m==3.22.0\u001b[0m\n",
      " \u001b[33m~\u001b[39m \u001b[1mpycryptodomex\u001b[0m\u001b[2m==3.22.0\u001b[0m\n",
      " \u001b[33m~\u001b[39m \u001b[1mpygments\u001b[0m\u001b[2m==2.19.1\u001b[0m\n",
      " \u001b[33m~\u001b[39m \u001b[1mpyskein\u001b[0m\u001b[2m==1.0\u001b[0m\n",
      " \u001b[33m~\u001b[39m \u001b[1mpython-dateutil\u001b[0m\u001b[2m==2.9.0.post0\u001b[0m\n",
      " \u001b[33m~\u001b[39m \u001b[1mpytz\u001b[0m\u001b[2m==2025.2\u001b[0m\n",
      " \u001b[33m~\u001b[39m \u001b[1mpyyaml\u001b[0m\u001b[2m==6.0.2\u001b[0m\n",
      " \u001b[33m~\u001b[39m \u001b[1mrequests\u001b[0m\u001b[2m==2.32.3\u001b[0m\n",
      " \u001b[33m~\u001b[39m \u001b[1mrich\u001b[0m\u001b[2m==13.9.4\u001b[0m\n",
      " \u001b[33m~\u001b[39m \u001b[1msix\u001b[0m\u001b[2m==1.17.0\u001b[0m\n",
      " \u001b[33m~\u001b[39m \u001b[1mtyping-extensions\u001b[0m\u001b[2m==4.13.0\u001b[0m\n",
      " \u001b[33m~\u001b[39m \u001b[1mtyping-validation\u001b[0m\u001b[2m==1.2.12\u001b[0m\n",
      " \u001b[33m~\u001b[39m \u001b[1mtzdata\u001b[0m\u001b[2m==2025.2\u001b[0m\n",
      " \u001b[33m~\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.3.0\u001b[0m\n",
      " \u001b[33m~\u001b[39m \u001b[1mwrapt\u001b[0m\u001b[2m==1.17.2\u001b[0m\n",
      " \u001b[33m~\u001b[39m \u001b[1mxarray\u001b[0m\u001b[2m==2025.3.0\u001b[0m\n",
      " \u001b[33m~\u001b[39m \u001b[1mzarr\u001b[0m\u001b[2m==3.0.6\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install xarray zarr multiformats git+https://github.com/dClimate/py-hamt.git --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82928721-6668-4e70-801c-575224f8973d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encryption Key used: b\"\\x89\\x037d\\xf6\\xbf2'\\xaf\\x92\\x1b&\\t\\x02\\x9d\\xc3\\x06\\x95\\xfbn\\xd3\\x07\\xc8\\xa1\\xe3JK'\\x8a\\xa2Wv\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import xarray as xr\n",
    "import requests\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import zarr.codecs\n",
    "from datetime import datetime\n",
    "from py_hamt import HAMT, IPFSStore, create_zarr_encryption_transformers, IPFSZarr3\n",
    "from multiformats import CID\n",
    "import numcodecs  # For compression if needed\n",
    "\n",
    "\n",
    "# Note: The encryption Key should be random, the below encryption key is just an exmaple bytes object of length 32\n",
    "encryption_key = os.urandom(32)  # Generates a secure 32-byte encryption key\n",
    "print(\"Encryption Key used:\", encryption_key)\n",
    "\n",
    "def prefetch_conus_data(\n",
    "    base_url: str = \"https://psl.noaa.gov/thredds/fileServer/Datasets/cpc_us_precip/RT/precip.V1.0.\",\n",
    "    start_year: int = 2007,\n",
    "    end_year: int = None,\n",
    ") -> list[str]:\n",
    "    \"\"\"\n",
    "    Generate a list of netCDF download URLs for CPC CONUS daily precipitation from start_year to end_year.\n",
    "\n",
    "    :param base_url: Prefix of the data location.\n",
    "    :param start_year: Earliest year of data to fetch.\n",
    "    :param end_year: Latest year of data to fetch; defaults to current year if None.\n",
    "    :return: A list of full download URLs, one per year.\n",
    "    \"\"\"\n",
    "    if end_year is None:\n",
    "        end_year = datetime.utcnow().year\n",
    "\n",
    "    download_links = []\n",
    "    for yr in range(start_year, end_year + 1):\n",
    "        download_url = f\"{base_url}{yr}.nc\"\n",
    "        download_links.append(download_url)\n",
    "\n",
    "    return download_links\n",
    "\n",
    "\n",
    "def fetch_data(\n",
    "    download_links: list[str],\n",
    "    local_dir: str = \"cpc_conus_netcdf\",\n",
    "    overwrite: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Download .nc files for each link in download_links.  \n",
    "    Uses `requests` (though `wget` via `subprocess` is another approach).\n",
    "\n",
    "    :param download_links: List of full .nc file URLs.\n",
    "    :param local_dir: Local directory in which to save .nc files.\n",
    "    :param overwrite: If False, skip download if file exists.\n",
    "    \"\"\"\n",
    "    os.makedirs(local_dir, exist_ok=True)\n",
    "\n",
    "    for url in download_links:\n",
    "        filename = url.split(\"/\")[-1]  # e.g. \"2007.nc\"\n",
    "        local_path = os.path.join(local_dir, filename)\n",
    "\n",
    "        if not overwrite and os.path.exists(local_path):\n",
    "            print(f\"File {local_path} exists; skipping download.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Downloading {url}\")\n",
    "        resp = requests.get(url, stream=True)\n",
    "        resp.raise_for_status()\n",
    "\n",
    "        with open(local_path, \"wb\") as f:\n",
    "            for chunk in resp.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "\n",
    "        print(f\"Saved to {local_path}\")\n",
    "\n",
    "\n",
    "def transform_to_zarr(\n",
    "    local_dir: str,\n",
    "    output_zarr: str,\n",
    "    varname: str = None,\n",
    "    start_date: str = None,\n",
    "    end_date: str = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Combine netCDF files from local_dir into a single xarray Dataset, optionally subsetting by date,\n",
    "    fix missing/fill values, and save to Zarr.\n",
    "\n",
    "    :param local_dir: Directory containing .nc files, each named like YEAR.nc\n",
    "    :param output_zarr: Path to the final Zarr store (e.g. \"cpc_conus.zarr\").\n",
    "    :param varname: Optional name of the variable to keep. If None, keep all.\n",
    "    :param start_date: Optional start date (YYYY-MM-DD). If provided, we do xarrayâ€™s .sel(time=slice(...)).\n",
    "    :param end_date: Optional end date (YYYY-MM-DD).\n",
    "    \"\"\"\n",
    "    nc_files = list(pathlib.Path(local_dir).glob(\"*.nc\"))\n",
    "    if not nc_files:\n",
    "        raise RuntimeError(f\"No netCDF files found in {local_dir}\")\n",
    "\n",
    "    print(f\"Reading {len(nc_files)} .nc files from {local_dir}\")\n",
    "\n",
    "    # Within a Jupyter Notebook Context setting parallel=False is to prevent read errors. Parallel reads via Dask can lead to file caching hiccups.\n",
    "    ds = xr.open_mfdataset([str(f) for f in nc_files], combine=\"by_coords\", parallel=False)\n",
    "\n",
    "    # If a variable name is provided, keep only that variable.\n",
    "    if varname is not None and varname in ds.data_vars:\n",
    "        ds = ds[[varname]]  # subset to that single variable\n",
    "\n",
    "    # Subset by time if start_date/end_date are provided\n",
    "    if start_date is not None or end_date is not None:\n",
    "        time_slice = slice(start_date, end_date)\n",
    "        ds = ds.sel(time=time_slice)\n",
    "\n",
    "    # Fix fill values or missing values if they exist\n",
    "    # ds = _fix_fill_values(ds)\n",
    "    ds = standardize_and_fix_fill_values(ds)\n",
    "\n",
    "    # Optionally, you can specify chunk sizes or compression\n",
    "    # below is a trivial example of chunking by time. Adjust as needed:\n",
    "    ds = ds.chunk({\"time\": 30})\n",
    "\n",
    "    # For demonstration, apply Blosc compression\n",
    "    for var in ds.data_vars:\n",
    "        ds[var].encoding[\"compressors\"] = zarr.codecs.BloscCodec()\n",
    "\n",
    "    print(f\"Writing dataset to Zarr => {output_zarr}\")\n",
    "    ds.to_zarr(output_zarr, mode=\"w\", consolidated=True)\n",
    "    print(\"Zarr creation complete.\")\n",
    "\n",
    "\n",
    "def load_zarr_to_ipfs(zarr_path: str, cid_out_path: str = None) -> str:\n",
    "    \"\"\"\n",
    "    Put the Zarr store onto IPFS using py-hamt. Returns the root CID as a string.\n",
    "    If cid_out_path is provided, also write the CID to a file.\n",
    "\n",
    "    :param zarr_path: Path to the local Zarr directory.\n",
    "    :param cid_out_path: Optional path to write the CID (e.g. \"cpc_conus.cid\").\n",
    "    :return: The root CID string\n",
    "    \"\"\"\n",
    "    print(f\"Loading {zarr_path} onto IPFS via py-hamt...\")\n",
    "    \n",
    "    # Encrypt only precip\n",
    "    # You can exclude data from being encrypted with exclude_vars=[\"precip\"] for example\n",
    "    encrypt, decrypt = create_zarr_encryption_transformers(\n",
    "        encryption_key, header=\"sample-header\".encode() \n",
    "    )\n",
    "    \n",
    "    hamt_store = HAMT(store=IPFSStore(), transformer_encode=encrypt, transformer_decode=decrypt)  # By default uses local IPFS daemon at 127.0.0.1:5001\n",
    "    ipfszarr3_store = IPFSZarr3(hamt_store)\n",
    "    ds = xr.open_zarr(zarr_path)\n",
    "    ds.to_zarr(store=ipfszarr3_store, mode=\"w\")\n",
    "\n",
    "    root_cid_str = str(hamt_store.root_node_id)\n",
    "    print(f\"Successfully wrote encrypted data to IPFS. Root CID = {root_cid_str}\")\n",
    "\n",
    "    if cid_out_path:\n",
    "        with open(cid_out_path, \"w\") as f:\n",
    "            f.write(root_cid_str + \"\\n\")\n",
    "\n",
    "    return root_cid_str\n",
    "\n",
    "def standardize_and_fix_fill_values(ds: xr.Dataset) -> xr.Dataset:\n",
    "    \"\"\"\n",
    "    Renames lat/lon, sorts coordinates, chunks dataset, fixes fill values, and applies compression.\n",
    "    \"\"\"\n",
    "    # 1. Rename lat/lon to standard naming\n",
    "    ds = ds.rename({\"lat\": \"latitude\", \"lon\": \"longitude\"})\n",
    "    \n",
    "    # 2. Sort coordinates to ascending\n",
    "    ds = ds.sortby(\"latitude\", ascending=True)\n",
    "    ds = ds.sortby(\"longitude\", ascending=True)\n",
    "    \n",
    "    # 3. Chunk the dataset (choose chunk sizes appropriate to your use case)\n",
    "    ds = ds.chunk({\"time\": 1769, \"latitude\": 24, \"longitude\": 24})\n",
    "    \n",
    "    for var in ds.data_vars:\n",
    "            da = ds[var]\n",
    "\n",
    "            # Apply compression\n",
    "            # clevel=9 means highest compression level (0-9 scale), we are optimizing for read speed\n",
    "            da.encoding[\"compressors\"] = zarr.codecs.BloscCodec(clevel=9)\n",
    "\n",
    "            # Prefer Fill Value over missing_value\n",
    "            da.encoding[\"_FillValue\"] = np.nan\n",
    "            if \"missing_value\" in da.attrs:\n",
    "                del da.attrs[\"missing_value\"]\n",
    "            if \"missing_value\" in da.encoding:\n",
    "                del da.encoding[\"missing_value\"]\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0642f6cd-4eec-4283-86e7-e63b6fd2ed76",
   "metadata": {},
   "source": [
    "After defining the various ETL steps above, it is simply a matter of calling each step in a sequential fashion. In the logs you should see the files being fetched for the dates provided. \n",
    "\n",
    "As you can see, 2007 is given as a start year and 2008 as an end year which is inclusive, and therefore will download the NetCDF files for both years(2007 and 2008). The data is then fetched, however, if the data already already exists locally it will not be downloaded again if the `overwrite` flag is set to false. The next step is to transform the netcdf files to zarr where the `end_date` only includes the first day of 2008 for example sake. Additionally if a `varname` is provided only that variable will be kept on the zarr. \n",
    "\n",
    "Lastly `load_zarr_to_ipfs` will return a CID (read the [Getting Started](./Getting%20Started.ipynb) to learn more) and write it out once the pipeline has completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1529dc4-3f2d-4c17-9678-f8f3dc3560e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded_data/gis/cpc_conus_netcdf_demo/precip.V1.0.2007.nc exists; skipping download.\n",
      "File downloaded_data/gis/cpc_conus_netcdf_demo/precip.V1.0.2008.nc exists; skipping download.\n",
      "Reading 2 .nc files from downloaded_data/gis/cpc_conus_netcdf_demo\n",
      "Writing dataset to Zarr => output_data/gis/cpc_conus_demo.zarr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.12/site-packages/zarr/api/asynchronous.py:203: UserWarning: Consolidated metadata is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zarr creation complete.\n",
      "Loading output_data/gis/cpc_conus_demo.zarr onto IPFS via py-hamt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.12/site-packages/zarr/api/asynchronous.py:203: UserWarning: Consolidated metadata is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully wrote encrypted data to IPFS. Root CID = bafyr4ichvciaq5utzhpjtsfzcct3cktp3ceh7uindwcuylixnxrorcwlfa\n",
      "Pipeline complete! The root CID is bafyr4ichvciaq5utzhpjtsfzcct3cktp3ceh7uindwcuylixnxrorcwlfa\n"
     ]
    }
   ],
   "source": [
    "# Example usage of the modular ETL pipeline\n",
    "\n",
    "# 1. Generate the list of CPC CONUS precipitation .nc URLs (only for years 2007 and 2008, end year is inclusive)\n",
    "download_links = prefetch_conus_data(\n",
    "    start_year=2007,\n",
    "    end_year=2008,  # If you want multiple years, pass a larger end_year\n",
    ")\n",
    "\n",
    "# 2. Download the actual .nc files\n",
    "fetch_data(\n",
    "    download_links=download_links,\n",
    "    local_dir=\"downloaded_data/gis/cpc_conus_netcdf_demo\",\n",
    "    overwrite=False,  # set True if you want to re-download\n",
    ")\n",
    "\n",
    "# 3. Transform the .nc files to Zarr, but only keep the first year \n",
    "transform_to_zarr(\n",
    "    local_dir=\"downloaded_data/gis/cpc_conus_netcdf_demo\",\n",
    "    output_zarr=\"output_data/gis/cpc_conus_demo.zarr\",\n",
    "    varname=\"precip\",         # If you don't know the exact var name, you can omit varname\n",
    "    start_date=\"2007-01-01\",  # Only keep data from Jan 1\n",
    "    end_date=\"2008-01-01\",    # through Jan 1 of 2008 (only includes day one from the second file)\n",
    ")\n",
    "\n",
    "# 4. Put the new \"cpc_conus_demo.zarr\" on IPFS\n",
    "root_cid = load_zarr_to_ipfs(\n",
    "    zarr_path=\"output_data/gis/cpc_conus_demo.zarr\",\n",
    "    cid_out_path=\"output_data/gis/cpc_conus_demo.cid\"\n",
    ")\n",
    "\n",
    "print(f\"Pipeline complete! The root CID is {root_cid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfb87f6-8379-4686-8de3-6dbbdecdbe50",
   "metadata": {},
   "source": [
    "# Opening and Reading the Dataset\n",
    "\n",
    "As you can see below, in a similar fashion to the Getting Started Notebook, we go ahead and provide the root hash(CID) of the newly ingested dataset into the HAMT store which is then loaded by xarray. We will show that attempting to read the data without the decrypt or proper decryption key will not work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54903789-3b4e-4b03-8d1f-0fad02b94380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New encryption key generated, which does not match the previous one: b'\\x9b\\xf2\\x83w\\xbb\\t\\xa0\\x12\\x0c\\xb0\\xf3&f\\t^\\xcf\\x07\\x97b\\xa0H\\xebz\\xfc\\xd5dsj\"k\\xacB'\n",
      "Decoded CID:\n",
      " bafyr4ichvciaq5utzhpjtsfzcct3cktp3ceh7uindwcuylixnxrorcwlfa \n",
      "\n"
     ]
    },
    {
     "ename": "CBORDecodingError",
     "evalue": "Failed to decode variable 'time': String bytes are not valid utf-8 bytes.\nAt byte #0: 66a6d8b650d2cf\n            ^^ string of length 6\nAt byte #1:   a6\n              ^^ invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m/opt/venv/lib/python3.12/site-packages/dag_cbor/decoding/__init__.py:219\u001b[0m, in \u001b[0;36m_decode_str\u001b[0;34m(stream, length, options)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 219\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[43mres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xa6 in position 0: invalid start byte",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mCBORDecodingError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/venv/lib/python3.12/site-packages/xarray/conventions.py:405\u001b[0m, in \u001b[0;36mdecode_cf_variables\u001b[0;34m(variables, attributes, concat_characters, mask_and_scale, decode_times, decode_coords, drop_variables, use_cftime, decode_timedelta)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 405\u001b[0m     new_vars[k] \u001b[38;5;241m=\u001b[39m \u001b[43mdecode_cf_variable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconcat_characters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_item_or_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconcat_characters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask_and_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_item_or_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask_and_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_item_or_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecode_times\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstack_char_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstack_char_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cftime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_item_or_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_cftime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_timedelta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_item_or_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecode_timedelta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/venv/lib/python3.12/site-packages/xarray/conventions.py:238\u001b[0m, in \u001b[0;36mdecode_cf_variable\u001b[0;34m(name, var, concat_characters, mask_and_scale, decode_times, decode_endianness, stack_char_dim, use_cftime, decode_timedelta)\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    230\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsage of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_cftime\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m as a kwarg is not allowed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCFDatetimeCoder\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instance is passed to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    ds = xr.open_dataset(decode_times=time_coder)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    237\u001b[0m             )\n\u001b[0;32m--> 238\u001b[0m     var \u001b[38;5;241m=\u001b[39m \u001b[43mdecode_times\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decode_endianness \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m var\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39misnative:\n",
      "File \u001b[0;32m/opt/venv/lib/python3.12/site-packages/xarray/coding/times.py:1380\u001b[0m, in \u001b[0;36mCFDatetimeCoder.decode\u001b[0;34m(self, variable, name)\u001b[0m\n\u001b[1;32m   1379\u001b[0m calendar \u001b[38;5;241m=\u001b[39m pop_to(attrs, encoding, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalendar\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1380\u001b[0m dtype \u001b[38;5;241m=\u001b[39m \u001b[43m_decode_cf_datetime_dtype\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalendar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_cftime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime_unit\u001b[49m\n\u001b[1;32m   1382\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1383\u001b[0m transform \u001b[38;5;241m=\u001b[39m partial(\n\u001b[1;32m   1384\u001b[0m     decode_cf_datetime,\n\u001b[1;32m   1385\u001b[0m     units\u001b[38;5;241m=\u001b[39munits,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1388\u001b[0m     time_unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_unit,\n\u001b[1;32m   1389\u001b[0m )\n",
      "File \u001b[0;32m/opt/venv/lib/python3.12/site-packages/xarray/coding/times.py:326\u001b[0m, in \u001b[0;36m_decode_cf_datetime_dtype\u001b[0;34m(data, units, calendar, use_cftime, time_unit)\u001b[0m\n\u001b[1;32m    324\u001b[0m values \u001b[38;5;241m=\u001b[39m indexing\u001b[38;5;241m.\u001b[39mImplicitToExplicitIndexingAdapter(indexing\u001b[38;5;241m.\u001b[39mas_indexable(data))\n\u001b[1;32m    325\u001b[0m example_value \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(\n\u001b[0;32m--> 326\u001b[0m     [to_numpy(\u001b[43mfirst_n_items\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m), to_numpy(last_item(values))]\n\u001b[1;32m    327\u001b[0m )\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/venv/lib/python3.12/site-packages/xarray/core/formatting.py:97\u001b[0m, in \u001b[0;36mfirst_n_items\u001b[0;34m(array, n_desired)\u001b[0m\n\u001b[1;32m     96\u001b[0m     array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39m_data\n\u001b[0;32m---> 97\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ravel(\u001b[43mto_duck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m)\u001b[49m)[:n_desired]\n",
      "File \u001b[0;32m/opt/venv/lib/python3.12/site-packages/xarray/namedarray/pycompat.py:143\u001b[0m, in \u001b[0;36mto_duck_array\u001b[0;34m(data, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExplicitlyIndexed \u001b[38;5;241m|\u001b[39m ImplicitToExplicitIndexingAdapter):\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_duck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[no-untyped-call, no-any-return]\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_duck_array(data):\n",
      "File \u001b[0;32m/opt/venv/lib/python3.12/site-packages/xarray/core/indexing.py:579\u001b[0m, in \u001b[0;36mImplicitToExplicitIndexingAdapter.get_duck_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_duck_array\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 579\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_duck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/venv/lib/python3.12/site-packages/xarray/core/indexing.py:653\u001b[0m, in \u001b[0;36mLazilyIndexedArray.get_duck_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    651\u001b[0m     \u001b[38;5;66;03m# If the array is not an ExplicitlyIndexedNDArrayMixin,\u001b[39;00m\n\u001b[1;32m    652\u001b[0m     \u001b[38;5;66;03m# it may wrap a BackendArray so use its __getitem__\u001b[39;00m\n\u001b[0;32m--> 653\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;66;03m# self.array[self.key] is now a numpy array when\u001b[39;00m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;66;03m# self.array is a BackendArray subclass\u001b[39;00m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;66;03m# and self.key is BasicIndexer((slice(None, None, None),))\u001b[39;00m\n\u001b[1;32m    658\u001b[0m \u001b[38;5;66;03m# so we need the explicit check for ExplicitlyIndexed\u001b[39;00m\n",
      "File \u001b[0;32m/opt/venv/lib/python3.12/site-packages/xarray/backends/zarr.py:223\u001b[0m, in \u001b[0;36mZarrArrayWrapper.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    222\u001b[0m     method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_oindex\n\u001b[0;32m--> 223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mindexing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplicit_indexing_adapter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndexingSupport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVECTORIZED\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/venv/lib/python3.12/site-packages/xarray/core/indexing.py:1014\u001b[0m, in \u001b[0;36mexplicit_indexing_adapter\u001b[0;34m(key, shape, indexing_support, raw_indexing_method)\u001b[0m\n\u001b[1;32m   1013\u001b[0m raw_key, numpy_indices \u001b[38;5;241m=\u001b[39m decompose_indexer(key, shape, indexing_support)\n\u001b[0;32m-> 1014\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mraw_indexing_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_key\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtuple\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m numpy_indices\u001b[38;5;241m.\u001b[39mtuple:\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;66;03m# index the loaded duck array\u001b[39;00m\n",
      "File \u001b[0;32m/opt/venv/lib/python3.12/site-packages/xarray/backends/zarr.py:213\u001b[0m, in \u001b[0;36mZarrArrayWrapper._getitem\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_getitem\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m--> 213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_array\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/opt/venv/lib/python3.12/site-packages/zarr/core/array.py:2425\u001b[0m, in \u001b[0;36mArray.__getitem__\u001b[0;34m(self, selection)\u001b[0m\n\u001b[1;32m   2424\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_pure_orthogonal_indexing(pure_selection, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim):\n\u001b[0;32m-> 2425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_orthogonal_selection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpure_selection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/venv/lib/python3.12/site-packages/zarr/_compat.py:43\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n",
      "File \u001b[0;32m/opt/venv/lib/python3.12/site-packages/zarr/core/array.py:2867\u001b[0m, in \u001b[0;36mArray.get_orthogonal_selection\u001b[0;34m(self, selection, out, fields, prototype)\u001b[0m\n\u001b[1;32m   2866\u001b[0m indexer \u001b[38;5;241m=\u001b[39m OrthogonalIndexer(selection, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mchunk_grid)\n\u001b[0;32m-> 2867\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2868\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_async_array\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_selection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2869\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprototype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprototype\u001b[49m\n\u001b[1;32m   2870\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2871\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/venv/lib/python3.12/site-packages/zarr/core/sync.py:163\u001b[0m, in \u001b[0;36msync\u001b[0;34m(coro, loop, timeout)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(return_result, \u001b[38;5;167;01mBaseException\u001b[39;00m):\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m return_result\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/venv/lib/python3.12/site-packages/zarr/core/sync.py:119\u001b[0m, in \u001b[0;36m_runner\u001b[0;34m(coro)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m coro\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "File \u001b[0;32m/opt/venv/lib/python3.12/site-packages/zarr/core/array.py:1287\u001b[0m, in \u001b[0;36mAsyncArray._get_selection\u001b[0;34m(self, indexer, prototype, out, fields)\u001b[0m\n\u001b[1;32m   1286\u001b[0m     \u001b[38;5;66;03m# reading chunks and decoding them\u001b[39;00m\n\u001b[0;32m-> 1287\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcodec_pipeline\u001b[38;5;241m.\u001b[39mread(\n\u001b[1;32m   1288\u001b[0m         [\n\u001b[1;32m   1289\u001b[0m             (\n\u001b[1;32m   1290\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstore_path \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mencode_chunk_key(chunk_coords),\n\u001b[1;32m   1291\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mget_chunk_spec(chunk_coords, _config, prototype\u001b[38;5;241m=\u001b[39mprototype),\n\u001b[1;32m   1292\u001b[0m                 chunk_selection,\n\u001b[1;32m   1293\u001b[0m                 out_selection,\n\u001b[1;32m   1294\u001b[0m                 is_complete_chunk,\n\u001b[1;32m   1295\u001b[0m             )\n\u001b[1;32m   1296\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m chunk_coords, chunk_selection, out_selection, is_complete_chunk \u001b[38;5;129;01min\u001b[39;00m indexer\n\u001b[1;32m   1297\u001b[0m         ],\n\u001b[1;32m   1298\u001b[0m         out_buffer,\n\u001b[1;32m   1299\u001b[0m         drop_axes\u001b[38;5;241m=\u001b[39mindexer\u001b[38;5;241m.\u001b[39mdrop_axes,\n\u001b[1;32m   1300\u001b[0m     )\n\u001b[1;32m   1301\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_buffer\u001b[38;5;241m.\u001b[39mas_ndarray_like()\n",
      "File \u001b[0;32m/opt/venv/lib/python3.12/site-packages/zarr/core/codec_pipeline.py:464\u001b[0m, in \u001b[0;36mBatchedCodecPipeline.read\u001b[0;34m(self, batch_info, out, drop_axes)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread\u001b[39m(\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    460\u001b[0m     batch_info: Iterable[\u001b[38;5;28mtuple\u001b[39m[ByteGetter, ArraySpec, SelectorTuple, SelectorTuple, \u001b[38;5;28mbool\u001b[39m]],\n\u001b[1;32m    461\u001b[0m     out: NDBuffer,\n\u001b[1;32m    462\u001b[0m     drop_axes: \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m (),\n\u001b[1;32m    463\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 464\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m concurrent_map(\n\u001b[1;32m    465\u001b[0m         [\n\u001b[1;32m    466\u001b[0m             (single_batch_info, out, drop_axes)\n\u001b[1;32m    467\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m single_batch_info \u001b[38;5;129;01min\u001b[39;00m batched(batch_info, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size)\n\u001b[1;32m    468\u001b[0m         ],\n\u001b[1;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_batch,\n\u001b[1;32m    470\u001b[0m         config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masync.concurrency\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    471\u001b[0m     )\n",
      "File \u001b[0;32m/opt/venv/lib/python3.12/site-packages/zarr/core/common.py:68\u001b[0m, in \u001b[0;36mconcurrent_map\u001b[0;34m(items, func, limit)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39mitem)\n\u001b[0;32m---> 68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39m[asyncio\u001b[38;5;241m.\u001b[39mensure_future(run(item)) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m items])\n",
      "File \u001b[0;32m/opt/venv/lib/python3.12/site-packages/zarr/core/common.py:66\u001b[0m, in \u001b[0;36mconcurrent_map.<locals>.run\u001b[0;34m(item)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m sem:\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39mitem)\n",
      "File \u001b[0;32m/opt/venv/lib/python3.12/site-packages/zarr/core/codec_pipeline.py:265\u001b[0m, in \u001b[0;36mBatchedCodecPipeline.read_batch\u001b[0;34m(self, batch_info, out, drop_axes)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 265\u001b[0m     chunk_bytes_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m concurrent_map(\n\u001b[1;32m    266\u001b[0m         [(byte_getter, array_spec\u001b[38;5;241m.\u001b[39mprototype) \u001b[38;5;28;01mfor\u001b[39;00m byte_getter, array_spec, \u001b[38;5;241m*\u001b[39m_ \u001b[38;5;129;01min\u001b[39;00m batch_info],\n\u001b[1;32m    267\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m byte_getter, prototype: byte_getter\u001b[38;5;241m.\u001b[39mget(prototype),\n\u001b[1;32m    268\u001b[0m         config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masync.concurrency\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    269\u001b[0m     )\n\u001b[1;32m    270\u001b[0m     chunk_array_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode_batch(\n\u001b[1;32m    271\u001b[0m         [\n\u001b[1;32m    272\u001b[0m             (chunk_bytes, chunk_spec)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    276\u001b[0m         ],\n\u001b[1;32m    277\u001b[0m     )\n",
      "File \u001b[0;32m/opt/venv/lib/python3.12/site-packages/zarr/core/common.py:68\u001b[0m, in \u001b[0;36mconcurrent_map\u001b[0;34m(items, func, limit)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39mitem)\n\u001b[0;32m---> 68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39m[asyncio\u001b[38;5;241m.\u001b[39mensure_future(run(item)) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m items])\n",
      "File \u001b[0;32m/opt/venv/lib/python3.12/site-packages/zarr/core/common.py:66\u001b[0m, in \u001b[0;36mconcurrent_map.<locals>.run\u001b[0;34m(item)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m sem:\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39mitem)\n",
      "File \u001b[0;32m/opt/venv/lib/python3.12/site-packages/zarr/storage/_common.py:124\u001b[0m, in \u001b[0;36mStorePath.get\u001b[0;34m(self, prototype, byte_range)\u001b[0m\n\u001b[1;32m    123\u001b[0m     prototype \u001b[38;5;241m=\u001b[39m default_buffer_prototype()\n\u001b[0;32m--> 124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstore\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath, prototype\u001b[38;5;241m=\u001b[39mprototype, byte_range\u001b[38;5;241m=\u001b[39mbyte_range)\n",
      "File \u001b[0;32m/opt/venv/lib/python3.12/site-packages/py_hamt/ipfszarr3.py:64\u001b[0m, in \u001b[0;36mIPFSZarr3.get\u001b[0;34m(self, key, prototype, byte_range)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget\u001b[39m(\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     60\u001b[0m     key: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m     61\u001b[0m     prototype: zarr\u001b[38;5;241m.\u001b[39mcore\u001b[38;5;241m.\u001b[39mbuffer\u001b[38;5;241m.\u001b[39mBufferPrototype,\n\u001b[1;32m     62\u001b[0m     byte_range: zarr\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mstore\u001b[38;5;241m.\u001b[39mByteRequest \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     63\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m zarr\u001b[38;5;241m.\u001b[39mcore\u001b[38;5;241m.\u001b[39mbuffer\u001b[38;5;241m.\u001b[39mBuffer \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhamt\u001b[49m:\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m<frozen _collections_abc>:813\u001b[0m, in \u001b[0;36m__contains__\u001b[0;34m(self, key)\u001b[0m\n",
      "File \u001b[0;32m/opt/venv/lib/python3.12/site-packages/py_hamt/hamt.py:543\u001b[0m, in \u001b[0;36mHAMT.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    542\u001b[0m     result_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer_decode(key, result_bytes)\n\u001b[0;32m--> 543\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdag_cbor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/venv/lib/python3.12/site-packages/dag_cbor/decoding/__init__.py:127\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m(stream_or_bytes, allow_concat, callback, require_multicodec, normalize_strings)\u001b[0m\n\u001b[1;32m    126\u001b[0m     stream \u001b[38;5;241m=\u001b[39m Stream(_stream)\n\u001b[0;32m--> 127\u001b[0m data, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_decode_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_concat:\n",
      "File \u001b[0;32m/opt/venv/lib/python3.12/site-packages/dag_cbor/decoding/__init__.py:149\u001b[0m, in \u001b[0;36m_decode_item\u001b[0;34m(stream, options)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;66;03m# Major types 0x2-0x6 and 0x7 (bool/null case):\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m     value, num_bytes_further_read \u001b[38;5;241m=\u001b[39m \u001b[43m_decoders\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmajor_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m     ret \u001b[38;5;241m=\u001b[39m (value, num_bytes_read\u001b[38;5;241m+\u001b[39mnum_bytes_further_read)\n",
      "File \u001b[0;32m/opt/venv/lib/python3.12/site-packages/dag_cbor/decoding/__init__.py:221\u001b[0m, in \u001b[0;36m_decode_str\u001b[0;34m(stream, length, options)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 221\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CBORDecodingError(_err\u001b[38;5;241m.\u001b[39m_unicode(stream, length, e\u001b[38;5;241m.\u001b[39mstart, e\u001b[38;5;241m.\u001b[39mend, e\u001b[38;5;241m.\u001b[39mreason)) \u001b[38;5;66;03m# pylint: disable = raise-missing-from\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnormalize_strings\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m options:\n",
      "\u001b[0;31mCBORDecodingError\u001b[0m: String bytes are not valid utf-8 bytes.\nAt byte #0: 66a6d8b650d2cf\n            ^^ string of length 6\nAt byte #1:   a6\n              ^^ invalid start byte",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mCBORDecodingError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m hamt \u001b[38;5;241m=\u001b[39m HAMT(store\u001b[38;5;241m=\u001b[39mIPFSStore(gateway_uri_stem\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://0.0.0.0:8080\u001b[39m\u001b[38;5;124m\"\u001b[39m), root_node_id\u001b[38;5;241m=\u001b[39mdecoded_root_cid)\n\u001b[1;32m     15\u001b[0m ipfszarr3_store \u001b[38;5;241m=\u001b[39m IPFSZarr3(hamt)\n\u001b[0;32m---> 16\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_zarr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mipfszarr3_store\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset(note the metadata is still accessible and unencrypted):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, ds, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTry printing out values without trying to decrypt at all:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/venv/lib/python3.12/site-packages/xarray/backends/zarr.py:1511\u001b[0m, in \u001b[0;36mopen_zarr\u001b[0;34m(store, group, synchronizer, chunks, decode_cf, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, consolidated, overwrite_encoded_chunks, chunk_store, storage_options, decode_timedelta, use_cftime, zarr_version, zarr_format, use_zarr_fill_value_as_mask, chunked_array_type, from_array_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m   1497\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   1498\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopen_zarr() got unexpected keyword arguments \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(kwargs\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m   1499\u001b[0m     )\n\u001b[1;32m   1501\u001b[0m backend_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1502\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msynchronizer\u001b[39m\u001b[38;5;124m\"\u001b[39m: synchronizer,\n\u001b[1;32m   1503\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconsolidated\u001b[39m\u001b[38;5;124m\"\u001b[39m: consolidated,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1508\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzarr_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: zarr_format,\n\u001b[1;32m   1509\u001b[0m }\n\u001b[0;32m-> 1511\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_cf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_cf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1515\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask_and_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask_and_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_times\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconcat_characters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcat_characters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_coords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_coords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzarr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked_array_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked_array_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrom_array_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_array_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackend_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_timedelta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_timedelta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1526\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cftime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cftime\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mzarr_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzarr_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1528\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_zarr_fill_value_as_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_zarr_fill_value_as_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m/opt/venv/lib/python3.12/site-packages/xarray/backends/api.py:687\u001b[0m, in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    675\u001b[0m decoders \u001b[38;5;241m=\u001b[39m _resolve_decoders_kwargs(\n\u001b[1;32m    676\u001b[0m     decode_cf,\n\u001b[1;32m    677\u001b[0m     open_backend_dataset_parameters\u001b[38;5;241m=\u001b[39mbackend\u001b[38;5;241m.\u001b[39mopen_dataset_parameters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    683\u001b[0m     decode_coords\u001b[38;5;241m=\u001b[39mdecode_coords,\n\u001b[1;32m    684\u001b[0m )\n\u001b[1;32m    686\u001b[0m overwrite_encoded_chunks \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite_encoded_chunks\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 687\u001b[0m backend_ds \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdecoders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    693\u001b[0m ds \u001b[38;5;241m=\u001b[39m _dataset_from_backend_dataset(\n\u001b[1;32m    694\u001b[0m     backend_ds,\n\u001b[1;32m    695\u001b[0m     filename_or_obj,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    706\u001b[0m )\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m/opt/venv/lib/python3.12/site-packages/xarray/backends/zarr.py:1601\u001b[0m, in \u001b[0;36mZarrBackendEntrypoint.open_dataset\u001b[0;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, group, mode, synchronizer, consolidated, chunk_store, storage_options, zarr_version, zarr_format, store, engine, use_zarr_fill_value_as_mask, cache_members)\u001b[0m\n\u001b[1;32m   1599\u001b[0m store_entrypoint \u001b[38;5;241m=\u001b[39m StoreBackendEntrypoint()\n\u001b[1;32m   1600\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m close_on_error(store):\n\u001b[0;32m-> 1601\u001b[0m     ds \u001b[38;5;241m=\u001b[39m \u001b[43mstore_entrypoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask_and_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask_and_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_times\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconcat_characters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcat_characters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1606\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_coords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_coords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1607\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdrop_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1608\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cftime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cftime\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_timedelta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_timedelta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1610\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1611\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m/opt/venv/lib/python3.12/site-packages/xarray/backends/store.py:47\u001b[0m, in \u001b[0;36mStoreBackendEntrypoint.open_dataset\u001b[0;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mvars\u001b[39m, attrs \u001b[38;5;241m=\u001b[39m filename_or_obj\u001b[38;5;241m.\u001b[39mload()\n\u001b[1;32m     45\u001b[0m encoding \u001b[38;5;241m=\u001b[39m filename_or_obj\u001b[38;5;241m.\u001b[39mget_encoding()\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28mvars\u001b[39m, attrs, coord_names \u001b[38;5;241m=\u001b[39m \u001b[43mconventions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_cf_variables\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mvars\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask_and_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask_and_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_times\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconcat_characters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcat_characters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_coords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_coords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cftime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cftime\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_timedelta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_timedelta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m ds \u001b[38;5;241m=\u001b[39m Dataset(\u001b[38;5;28mvars\u001b[39m, attrs\u001b[38;5;241m=\u001b[39mattrs)\n\u001b[1;32m     60\u001b[0m ds \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mset_coords(coord_names\u001b[38;5;241m.\u001b[39mintersection(\u001b[38;5;28mvars\u001b[39m))\n",
      "File \u001b[0;32m/opt/venv/lib/python3.12/site-packages/xarray/conventions.py:416\u001b[0m, in \u001b[0;36mdecode_cf_variables\u001b[0;34m(variables, attributes, concat_characters, mask_and_scale, decode_times, decode_coords, drop_variables, use_cftime, decode_timedelta)\u001b[0m\n\u001b[1;32m    405\u001b[0m     new_vars[k] \u001b[38;5;241m=\u001b[39m decode_cf_variable(\n\u001b[1;32m    406\u001b[0m         k,\n\u001b[1;32m    407\u001b[0m         v,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    413\u001b[0m         decode_timedelta\u001b[38;5;241m=\u001b[39m_item_or_default(decode_timedelta, k, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    414\u001b[0m     )\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 416\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(e)(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to decode variable \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decode_coords \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoordinates\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    418\u001b[0m     var_attrs \u001b[38;5;241m=\u001b[39m new_vars[k]\u001b[38;5;241m.\u001b[39mattrs\n",
      "\u001b[0;31mCBORDecodingError\u001b[0m: Failed to decode variable 'time': String bytes are not valid utf-8 bytes.\nAt byte #0: 66a6d8b650d2cf\n            ^^ string of length 6\nAt byte #1:   a6\n              ^^ invalid start byte"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "from py_hamt import HAMT, IPFSZarr3, IPFSStore\n",
    "from multiformats import CID\n",
    "\n",
    "# Generate a new encryption key which does not match the originally generated one\n",
    "wrong_encryption_key = os.urandom(32)\n",
    "print(\"New encryption key generated, which does not match the previous one:\", wrong_encryption_key)\n",
    "\n",
    "decoded_root_cid = CID.decode(root_cid)\n",
    "print(\"Decoded CID:\\n\", decoded_root_cid, \"\\n\")\n",
    "\n",
    "\n",
    "# Create HAMT instance using the IPFSStore connecting to your locally running IPFS Gateway from your local running IPFS Node\n",
    "hamt = HAMT(store=IPFSStore(gateway_uri_stem=\"http://0.0.0.0:8080\"), root_node_id=decoded_root_cid)\n",
    "ipfszarr3_store = IPFSZarr3(hamt)\n",
    "ds = xr.open_zarr(store=ipfszarr3_store)\n",
    "\n",
    "print(\"Dataset(note the metadata is still accessible and unencrypted):\\n\", ds, \"\\n\")\n",
    "print(\"Try printing out values without trying to decrypt at all:\")\n",
    "try:\n",
    "\n",
    "    print(\"Dataset values:\", ds.precip.values)\n",
    "except:\n",
    "    print(\"Error: Could not read encrypted values as expected\\n\")\n",
    "\n",
    "# Use bad encryption key\n",
    "encrypt, decrypt = create_zarr_encryption_transformers(\n",
    "    wrong_encryption_key, header=\"sample-header\".encode() \n",
    ")\n",
    "\n",
    "hamt = HAMT(store=IPFSStore(gateway_uri_stem=\"http://0.0.0.0:8080\"), root_node_id=decoded_root_cid, transformer_encode=encrypt, transformer_decode=decrypt)\n",
    "ipfszarr3_store = IPFSZarr3(hamt)\n",
    "ds = xr.open_zarr(store=ipfszarr3_store)\n",
    "\n",
    "print(\"Try printing out values using the wrong key:\")\n",
    "try:\n",
    "\n",
    "    print(ds.precip.values)\n",
    "except:\n",
    "    print(\"Error: Could not read encrypted values as expected due to wrong key\\n\")\n",
    "\n",
    "\n",
    "# Generate the transformers again with the same encryption_key used prior\n",
    "encrypt, decrypt = create_zarr_encryption_transformers(\n",
    "    encryption_key, header=\"sample-header\".encode() \n",
    ")\n",
    "\n",
    "hamt = HAMT(store=IPFSStore(gateway_uri_stem=\"http://0.0.0.0:8080\"), root_node_id=decoded_root_cid, transformer_encode=encrypt, transformer_decode=decrypt)\n",
    "ipfszarr3_store = IPFSZarr3(hamt)\n",
    "ds = xr.open_zarr(store=ipfszarr3_store)\n",
    "\n",
    "print(\"Successfully retrieved and decrypted the encrypted dataset using the original key\\n\")\n",
    "try:\n",
    "    # Let's get data for New York\n",
    "    lon_range = (360 - 74.25, 360 - 73.7)  # Converted to 285.75 - 286.3\n",
    "    lat_range = (40.5, 45.0)  # Latitude remains the same\n",
    "    \n",
    "    ny_precip = ds.sel(latitude=slice(*lat_range), longitude=slice(*lon_range))\n",
    "    print(ny_precip.precip.values)\n",
    "except:\n",
    "    print(\"Could not read encrypted values as expected due to wrong key\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641ed636-7962-4bf7-8497-7c3e15238829",
   "metadata": {},
   "source": [
    "# Plotting the Data\n",
    "\n",
    "To illustrate the data we go ahead and plot some of the precipitation information for New York using encrypted data :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ec4e87-b17c-4a41-99ce-4a63c14f6a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lon_range = (360 - 74.25, 360 - 73.7)  # Converted to 285.75 - 286.3\n",
    "lat_range = (40.5, 45.0)  # Latitude remains the same\n",
    "\n",
    "ny_precip = ds.sel(latitude=slice(*lat_range), longitude=slice(*lon_range))\n",
    "print(ny_precip)\n",
    "\n",
    "if ny_precip.precip.count() > 0:\n",
    "    print(\"Precipitation data exists for this range.\")\n",
    "else:\n",
    "    print(\"No precipitation data for the specified range.\")\n",
    "\n",
    "# Compute the average precipitation over the region\n",
    "ny_precip_mean = ny_precip.precip.mean(dim=[\"latitude\", \"longitude\"])\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "ny_precip_mean.plot(marker='o', color='blue')\n",
    "plt.title(\"Precipitation in New York (Daily Mean)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Precipitation (mm)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348133b0-f090-4bc2-92aa-3dabaf07beb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
